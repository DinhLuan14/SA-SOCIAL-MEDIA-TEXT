{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_UIT_VSMEC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtAWSwpfhuf81xwI2ZXsh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinhluan14/Classification-of-social-media-text-in-Vietnamese/blob/main/LSTM_UIT_VSMEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8kv09LKhSD_"
      },
      "source": [
        "#**Dowload dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyv12Ybux_fR"
      },
      "source": [
        "# valid\n",
        "!gdown --id 1ch_F1fRqgBuT5bLLk6CbJoHO1TpvEEnQ \n",
        "# train\n",
        "!gdown --id 1svJAKgX2W6CzLk5wWt4A5oKnn25yNha9\n",
        "# test\n",
        "!gdown --id 1IqxO0hhfVyNbDWkbbwyuz9NGM6G_md_R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcw0PH6JeTSg",
        "outputId": "e6d349af-ba96-4ed3-fe3a-620b442ed353"
      },
      "source": [
        "# Import\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "\n",
        "import keras\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE6VOlG5x8hC"
      },
      "source": [
        "#Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSVBV_LhdqwX"
      },
      "source": [
        "## Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "hwMIy09Ld8jp",
        "outputId": "6faddc63-5584-4e96-d09e-9084a57f2aaa"
      },
      "source": [
        "df_train = pd.read_excel(\"/content/train_nor_811.xlsx\",index_col = None,usecols = \"B,C:AA\").reindex(columns=[\"Sentence\",\"Emotion\"])\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))</td>\n",
              "      <td>Enjoyment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...</td>\n",
              "      <td>Enjoyment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5543</th>\n",
              "      <td>ƒë∆∞·ªùng c·ªßa nh√† c·ª• hay sao m√† c·ª• c·∫•m ng∆∞·ªùi ta ƒë·ªó...</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5544</th>\n",
              "      <td>nh√¨n m·∫∑t h√©o queo lu√¥n</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5545</th>\n",
              "      <td>tao ƒëi xe m√°y m·ªói l·∫ßn mu·ªën ƒë·ªÉ xe ƒëi ƒë√¢u l√† phi...</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5546</th>\n",
              "      <td>th√≠ch th√¢n h√¨nh boss r·ªìi nhan üòå</td>\n",
              "      <td>Enjoyment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5547</th>\n",
              "      <td>∆∞·ªõc m∆° nh·ªè nhoi c·ªßa tao l√† ƒë∆∞·ª£c l√†m ch·ªã m√† kh√¥...</td>\n",
              "      <td>Sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5548 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Sentence    Emotion\n",
              "0                 cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°      Other\n",
              "1     cho ƒë√°ng ƒë·ªùi con qu·ª∑ . v·ªÅ nh√† l√¥i con nh√† m√†y ...    Disgust\n",
              "2     lo h·ªçc ƒëi . y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc...    Disgust\n",
              "3       u·ªõc g√¨ sau n√†y v·ªÅ gi√† v·∫´n c√≥ th·ªÉ nh∆∞ c·ª• n√†y :))  Enjoyment\n",
              "4     m·ªói l·∫ßn c√≥ video c·ªßa con l√† c·ª© coi ƒëi coi l·∫°i ...  Enjoyment\n",
              "...                                                 ...        ...\n",
              "5543  ƒë∆∞·ªùng c·ªßa nh√† c·ª• hay sao m√† c·ª• c·∫•m ng∆∞·ªùi ta ƒë·ªó...    Disgust\n",
              "5544                             nh√¨n m·∫∑t h√©o queo lu√¥n      Other\n",
              "5545  tao ƒëi xe m√°y m·ªói l·∫ßn mu·ªën ƒë·ªÉ xe ƒëi ƒë√¢u l√† phi...      Other\n",
              "5546                    th√≠ch th√¢n h√¨nh boss r·ªìi nhan üòå  Enjoyment\n",
              "5547  ∆∞·ªõc m∆° nh·ªè nhoi c·ªßa tao l√† ƒë∆∞·ª£c l√†m ch·ªã m√† kh√¥...    Sadness\n",
              "\n",
              "[5548 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV6b0b5LdyRm"
      },
      "source": [
        "## Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34eFsdE2d9YZ"
      },
      "source": [
        "df_test = pd.read_excel(\"/content/test_nor_811.xlsx\",index_col = None,usecols = \"B,C:AA\").reindex(columns=[\"Sentence\",\"Emotion\"])\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC0bhf7cd19P"
      },
      "source": [
        "##Valid set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhGRA49pd4kL"
      },
      "source": [
        "df_valid = pd.read_excel(\"/content/valid_nor_811.xlsx\",index_col = None,usecols = \"B,C:AA\").reindex(columns=[\"Sentence\",\"Emotion\"])\n",
        "df_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pBgF2jVhEOT"
      },
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxuoHorimFOv"
      },
      "source": [
        "import re\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "# BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "# STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    # text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('.', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    # text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text\n",
        "# df['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(clean_text)\n",
        "df_train[\"Sentence\"] = df_train[\"Sentence\"].apply(clean_text)\n",
        "df_test[\"Sentence\"] = df_test[\"Sentence\"].apply(clean_text)\n",
        "df_valid[\"Sentence\"] = df_valid[\"Sentence\"].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjBQoNOl0LvP"
      },
      "source": [
        "df_train[\"Emotion\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOYX2Uo51Tbf"
      },
      "source": [
        "#Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmSovYCy1Sbq",
        "outputId": "8e695a9c-8bff-4cf1-9f82-161872190123"
      },
      "source": [
        "Emotion_train = pd.get_dummies(df_train['Emotion']).values\n",
        "print('Shape of label train tensor:', Emotion_train.shape)\n",
        "Emotion_valid = pd.get_dummies(df_valid['Emotion']).values\n",
        "print('Shape of label dev tensor:', Emotion_valid.shape)\n",
        "Emotion_test = pd.get_dummies(df_test['Emotion']).values\n",
        "print('Shape of label test tensor:', Emotion_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label train tensor: (5548, 7)\n",
            "Shape of label dev tensor: (686, 7)\n",
            "Shape of label test tensor: (693, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBChrW7N2EMj",
        "outputId": "9c8b6bea-5cbb-426d-9e92-b03f48795746"
      },
      "source": [
        "Sentence_test = df_test['Sentence']\n",
        "Sentence_test = np.array(Sentence_test)\n",
        "# Sentence_test\n",
        "Sentence_valid = df_valid['Sentence']\n",
        "Sentence_valid = np.array(Sentence_valid)\n",
        "# Sentence_valid.shape\n",
        "Sentence_train = df_train['Sentence']\n",
        "Sentence_train = np.array(Sentence_train)\n",
        "Sentence_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cho m√¨nh xin b√†i nh·∫°c t√™n l√† g√¨ v·ªõi ·∫°',\n",
              "       'cho ƒë√°ng ƒë·ªùi con qu·ª∑  v·ªÅ nh√† l√¥i con nh√† m√†y ra m√† ƒë√°nh üò°',\n",
              "       'lo h·ªçc ƒëi  y√™u ƒë∆∞∆°ng lol g√¨ hay l·∫°i th√≠ch h·ªçc sinh h·ªçc', ...,\n",
              "       'tao ƒëi xe m√°y m·ªói l·∫ßn mu·ªën ƒë·ªÉ xe ƒëi ƒë√¢u l√† phi m·∫π n√≥ v√†o qu√°n net g·ª≠i ƒë·∫•y r·ªìi ƒëi ra ƒë√©o m·∫•t ph√≠',\n",
              "       'th√≠ch th√¢n h√¨nh boss r·ªìi nhan üòå',\n",
              "       '∆∞·ªõc m∆° nh·ªè nhoi c·ªßa tao l√† ƒë∆∞·ª£c l√†m ch·ªã m√† kh√¥ng th·ªÉ n√†o l√†m ƒë∆∞·ª£c huhu'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULo4iNny2one"
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 64 # chieu cua embedding\n",
        "max_length = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJqgZXUo2qjC",
        "outputId": "afcdae68-1608-450e-e2b5-a5540a2554f2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer  # th∆∞ vi·ªán t√°ch t·ª´\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # \n",
        "# tokenize c√°c c√¢u vƒÉn sang chu·ªói index v√† padding c√¢u vƒÉn v·ªÅ c≈©ng m·ªôt ƒë·ªô d√†i.\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(Sentence_train)\n",
        "\n",
        "Sentence_train_sequences = tokenizer.texts_to_sequences(Sentence_train)\n",
        "padded_Sentence_train_sequences = pad_sequences(Sentence_train_sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "padded_Sentence_train_sequences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5548, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVVGoAmE3Dm5",
        "outputId": "e6a619b4-ea6b-4ff1-d52e-7416fc29e2d5"
      },
      "source": [
        "Sentence_valid_sequences = tokenizer.texts_to_sequences(Sentence_valid)\n",
        "padded_Sentence_valid_sequences = pad_sequences(Sentence_valid_sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "padded_Sentence_valid_sequences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(686, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAC-zQKG3GXv",
        "outputId": "b08ce79d-7f76-4502-f6d6-e1c440331cd7"
      },
      "source": [
        "Sentence_test_sequences = tokenizer.texts_to_sequences(Sentence_test)\n",
        "padded_Sentence_test_sequences = pad_sequences(Sentence_test_sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "padded_Sentence_test_sequences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(693, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9rohCvH3G7y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM,SpatialDropout1D, Dense, Flatten,Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3C-xdNf3J35"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ebVWdI5NUK"
      },
      "source": [
        "model.fit(padded_Sentence_train_sequences, Emotion_train, epochs=10, batch_size=32,validation_data=(padded_Sentence_valid_sequences, Emotion_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNH5yd6r5tTk"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM,SpatialDropout1D, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model1.add(SpatialDropout1D(0.2))\n",
        "model1.add(Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0)))\n",
        "model1.add(Dense(7, activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wea4DGaR54hu"
      },
      "source": [
        "model1.fit(padded_Sentence_train_sequences, Emotion_train, epochs=10, batch_size=32,validation_data=(padded_Sentence_valid_sequences, Emotion_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTiF-W3P6uZ1",
        "outputId": "6a9e1344-34df-4dac-ead2-15c530ed7980"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2jlhEnv65EO",
        "outputId": "d59b0489-2d00-4ec2-b63a-f981f273fdcb"
      },
      "source": [
        "cd /content/drive/MyDrive/LSTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQc8IILj66H0"
      },
      "source": [
        "model.save(\"LSTM.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzVBkaGf6_w1"
      },
      "source": [
        "model1.save(\"LSTM1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAWnm3Xx6k78",
        "outputId": "05d5ba2e-db59-41ac-97b2-99714950396d"
      },
      "source": [
        "sents_pred = model.predict(padded_Sentence_test_sequences)\n",
        "sents_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(693, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22YXnLSv7PuR",
        "outputId": "e5e0a475-cc97-4a4e-e126-fbb0d79e980b"
      },
      "source": [
        "sents_pred = (sents_pred > 0.5)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "accuracy_score(Emotion_test,sents_pred )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4675324675324675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XKzpqQm7XPK",
        "outputId": "184006f7-d2ea-40de-bbc8-aa9f640a3327"
      },
      "source": [
        "print(classification_report(Emotion_test,sents_pred))\n",
        "print(\"Accuracy: \\t\",accuracy_score(Emotion_test,sents_pred))\n",
        "print(\"F1-Score: \\t\",f1_score(Emotion_test,sents_pred, average=\"macro\"))\n",
        "print(\"Precision: \\t\",precision_score(Emotion_test,sents_pred, average=\"macro\"))\n",
        "print(\"Recall: \\t\",recall_score(Emotion_test,sents_pred, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.25      0.33        40\n",
            "           1       0.56      0.48      0.52       132\n",
            "           2       0.61      0.60      0.60       193\n",
            "           3       0.68      0.57      0.62        46\n",
            "           4       0.35      0.37      0.36       129\n",
            "           5       0.69      0.45      0.54       116\n",
            "           6       0.56      0.24      0.34        37\n",
            "\n",
            "   micro avg       0.55      0.47      0.51       693\n",
            "   macro avg       0.57      0.42      0.47       693\n",
            "weighted avg       0.56      0.47      0.50       693\n",
            " samples avg       0.47      0.47      0.47       693\n",
            "\n",
            "Accuracy: \t 0.4675324675324675\n",
            "F1-Score: \t 0.47468144379561095\n",
            "Precision: \t 0.5665843817930308\n",
            "Recall: \t 0.42279041814294965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khsaJx4p-gZV"
      },
      "source": [
        "#Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiSpPKWD-dAR"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_nb = confusion_matrix(Emotion_test.argmax(axis=1),sents_pred.argmax(axis=1))\n",
        "cm_nb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkknvQHz-j_I"
      },
      "source": [
        "set(df_train['Emotion'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfa240r--nb9"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "y_train = le.fit_transform(df_train[\"Emotion\"])\n",
        "\n",
        "plt.figure(figsize=(17,6))\n",
        "plt.title('Confusion Matrix: Naive Bayes', fontsize=20)\n",
        "cm_nb = confusion_matrix(Emotion_test.argmax(axis=1),sents_pred.argmax(axis=1))\n",
        "# df_cm_nb = pd.DataFrame(cm_nb, index=np.unique(le.inverse_transform(y_train)), columns=np.unique(le.inverse_transform(sents_pred)))\n",
        "df_cm_nb = pd.DataFrame(cm_nb, index=['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Surprise'], columns=['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Surprise'])\n",
        "sns.heatmap(df_cm_nb, annot=True, square=True, annot_kws={\"size\": 16}, fmt='2g', cmap='Greens')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}